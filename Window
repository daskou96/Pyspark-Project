from pyspark.sql import *
from pyspark.sql import functions as f
from lib.logger import Log4j





if __name__ == '__main__':

    spark = SparkSession.builder.appName('aggdemo').master("local[2]").getOrCreate()
    logger = Log4j(spark)

    df = spark.read.csv("data/sales_info.csv",inferSchema=True,header=True)

sdf = Window.partitionBy("Company").orderBy("Company").rowsBetween(Window.unboundedPreceding,Window.currentRow)

df.withColumn("Data",f.sum("Sales").over(sdf)).show()
